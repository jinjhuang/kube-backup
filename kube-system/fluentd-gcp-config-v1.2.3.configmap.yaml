apiVersion: v1
data:
  containers.input.conf: "# This configuration file for Fluentd is used\n# to watch\
    \ changes to Docker log files that live in the\n# directory /var/lib/docker/containers/\
    \ and are symbolically\n# linked to from the /var/log/containers directory using\
    \ names that capture the\n# pod name and container name. These logs are then submitted\
    \ to\n# Google Cloud Logging which assumes the installation of the cloud-logging\
    \ plug-in.\n#\n# Example\n# =======\n# A line in the Docker log file might look\
    \ like this JSON:\n#\n# {\"log\":\"2014/09/25 21:15:03 Got request with path wombat\\\
    \\n\",\n#  \"stream\":\"stderr\",\n#   \"time\":\"2014-09-25T21:15:03.499185026Z\"\
    }\n#\n# The record reformer is used to write the tag to focus on the pod name\n\
    # and the Kubernetes container name. For example a Docker container's logs\n#\
    \ might be in the directory:\n#  /var/lib/docker/containers/997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b\n\
    # and in the file:\n#  997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b-json.log\n\
    # where 997599971ee6... is the Docker ID of the running container.\n# The Kubernetes\
    \ kubelet makes a symbolic link to this file on the host machine\n# in the /var/log/containers\
    \ directory which includes the pod name and the Kubernetes\n# container name:\n\
    #    synthetic-logger-0.25lps-pod_default-synth-lgr-997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b.log\n\
    #    ->\n#    /var/lib/docker/containers/997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b/997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b-json.log\n\
    # The /var/log directory on the host is mapped to the /var/log directory in the\
    \ container\n# running this instance of Fluentd and we end up collecting the file:\n\
    #   /var/log/containers/synthetic-logger-0.25lps-pod_default-synth-lgr-997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b.log\n\
    # This results in the tag:\n#  var.log.containers.synthetic-logger-0.25lps-pod_default-synth-lgr-997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b.log\n\
    # The record reformer is used is discard the var.log.containers prefix and\n#\
    \ the Docker container ID suffix and \"kubernetes.\" is pre-pended giving the\
    \ tag:\n#   kubernetes.synthetic-logger-0.25lps-pod_default-synth-lgr\n# Tag is\
    \ then parsed by google_cloud plugin and translated to the metadata,\n# visible\
    \ in the log viewer\n\n# Json Log Example:\n# {\"log\":\"[info:2016-02-16T16:04:05.930-08:00]\
    \ Some log text here\\n\",\"stream\":\"stdout\",\"time\":\"2016-02-17T00:04:05.931087621Z\"\
    }\n# CRI Log Example:\n# 2016-02-17T00:04:05.931087621Z stdout F [info:2016-02-16T16:04:05.930-08:00]\
    \ Some log text here\n<source>\n  type tail\n  path /var/log/containers/*.log\n\
    \  pos_file /var/log/gcp-containers.log.pos\n  tag reform.*\n  read_from_head\
    \ true\n  format multi_format\n  <pattern>\n    format json\n    time_key time\n\
    \    time_format %Y-%m-%dT%H:%M:%S.%NZ\n  </pattern>\n  <pattern>\n    format\
    \ /^(?<time>.+) (?<stream>stdout|stderr) [^ ]* (?<log>.*)$/\n    time_format %Y-%m-%dT%H:%M:%S.%N%:z\n\
    \  </pattern>\n</source>\n\n<filter reform.**>\n  type parser\n  format /^(?<severity>\\\
    w)(?<time>\\d{4} [^\\s]*)\\s+(?<pid>\\d+)\\s+(?<source>[^ \\]]+)\\] (?<log>.*)/\n\
    \  reserve_data true\n  suppress_parse_error_log true\n  key_name log\n</filter>\n\
    \n<match reform.**>\n  type record_reformer\n  enable_ruby true\n  tag raw.kubernetes.${tag_suffix[4].split('-')[0..-2].join('-')}\n\
    </match>\n\n# Detect exceptions in the log output and forward them as one log\
    \ entry.\n<match raw.kubernetes.**>\n  @type detect_exceptions\n\n  remove_tag_prefix\
    \ raw\n  message log\n  stream stream\n  multiline_flush_interval 5\n  max_bytes\
    \ 500000\n  max_lines 1000\n</match>"
  monitoring.conf: "# Prometheus monitoring\n<source>\n  @type prometheus\n  port\
    \ 31337\n</source>\n\n<source>\n  @type prometheus_monitor\n</source>\n\n# This\
    \ source is used to acquire approximate process start timestamp,\n# which purpose\
    \ is explained before the corresponding output plugin.\n<source>\n  @type exec\n\
    \  command /bin/sh -c 'date +%s'\n  tag process_start\n  time_format %Y-%m-%d\
    \ %H:%M:%S\n  keys process_start_timestamp\n</source>\n\n# This filter is used\
    \ to convert process start timestamp to integer\n# value for correct ingestion\
    \ in the prometheus output plugin.\n<filter process_start>\n  @type record_transformer\n\
    \  enable_ruby true\n  auto_typecast true\n  <record>\n    process_start_timestamp\
    \ ${record[\"process_start_timestamp\"].to_i}\n  </record>\n</filter>"
  output.conf: "# This match is placed before the all-matching output to provide metric\n\
    # exporter with a process start timestamp for correct exporting of\n# cumulative\
    \ metrics to Stackdriver.\n<match process_start>\n  @type prometheus\n\n  <metric>\n\
    \    type gauge\n    name process_start_time_seconds\n    desc Timestamp of the\
    \ process start in seconds\n    key process_start_timestamp\n  </metric>\n</match>\n\
    \n# This filter allows to count the number of log entries read by fluentd\n# before\
    \ they are processed by the output plugin. This in turn allows to\n# monitor the\
    \ number of log entries that were read but never sent, e.g.\n# because of liveness\
    \ probe removing buffer.\n<filter **>\n  @type prometheus\n  <metric>\n    type\
    \ counter\n    name logging_entry_count\n    desc Total number of log entries\
    \ generated by either application containers or system components\n  </metric>\n\
    </filter>\n\n# TODO(instrumentation): Reconsider this workaround later.\n# Trim\
    \ the entries which exceed slightly less than 100KB, to avoid\n# dropping them.\
    \ It is a necessity, because Stackdriver only supports\n# entries that are up\
    \ to 100KB in size.\n<filter kubernetes.**>\n  @type record_transformer\n  enable_ruby\
    \ true\n  <record>\n    log ${record['log'].length > 100000 ? \"[Trimmed]#{record['log'][0..100000]}...\"\
    \ : record['log']}\n  </record>\n</filter>\n\n# We use 2 output stanzas - one\
    \ to handle the container logs and one to handle\n# the node daemon logs, the\
    \ latter of which explicitly sends its logs to the\n# compute.googleapis.com service\
    \ rather than container.googleapis.com to keep\n# them separate since most users\
    \ don't care about the node logs.\n<match kubernetes.**>\n  @type google_cloud\n\
    \n  # Try to detect JSON formatted log entries.\n  detect_json true\n  # Collect\
    \ metrics in Prometheus registry about plugin activity.\n  enable_monitoring true\n\
    \  monitoring_type prometheus\n  # Set the buffer type to file to improve the\
    \ reliability and reduce the memory consumption\n  buffer_type file\n  buffer_path\
    \ /var/log/fluentd-buffers/kubernetes.containers.buffer\n  # Set queue_full action\
    \ to block because we want to pause gracefully\n  # in case of the off-the-limits\
    \ load instead of throwing an exception\n  buffer_queue_full_action block\n  #\
    \ Set the chunk limit conservatively to avoid exceeding the recommended\n  # chunk\
    \ size of 5MB per write request.\n  buffer_chunk_limit 1M\n  # Cap the combined\
    \ memory usage of this buffer and the one below to\n  # 1MiB/chunk * (6 + 2) chunks\
    \ = 8 MiB\n  buffer_queue_limit 6\n  # Never wait more than 5 seconds before flushing\
    \ logs in the non-error case.\n  flush_interval 5s\n  # Never wait longer than\
    \ 30 seconds between retries.\n  max_retry_wait 30\n  # Disable the limit on the\
    \ number of retries (retry forever).\n  disable_retry_limit\n  # Use multiple\
    \ threads for processing.\n  num_threads 2\n</match>\n\n# Keep a smaller buffer\
    \ here since these logs are less important than the user's\n# container logs.\n\
    <match **>\n  @type google_cloud\n\n  detect_json true\n  enable_monitoring true\n\
    \  monitoring_type prometheus\n  detect_subservice false\n  buffer_type file\n\
    \  buffer_path /var/log/fluentd-buffers/kubernetes.system.buffer\n  buffer_queue_full_action\
    \ block\n  buffer_chunk_limit 1M\n  buffer_queue_limit 2\n  flush_interval 5s\n\
    \  max_retry_wait 30\n  disable_retry_limit\n  num_threads 2\n</match>"
  system.input.conf: "# Example:\n# 2015-12-21 23:17:22,066 [salt.state       ][INFO\
    \    ] Completed state [net.ipv4.ip_forward] at time 23:17:22.066081\n<source>\n\
    \  type tail\n  format /^(?<time>[^ ]* [^ ,]*)[^\\[]*\\[[^\\]]*\\]\\[(?<severity>[^\
    \ \\]]*) *\\] (?<message>.*)$/\n  time_format %Y-%m-%d %H:%M:%S\n  path /var/log/salt/minion\n\
    \  pos_file /var/log/gcp-salt.pos\n  tag salt\n</source>\n\n# Example:\n# Dec\
    \ 21 23:17:22 gke-foo-1-1-4b5cbd14-node-4eoj startupscript: Finished running startup\
    \ script /var/run/google.startup.script\n<source>\n  type tail\n  format syslog\n\
    \  path /var/log/startupscript.log\n  pos_file /var/log/gcp-startupscript.log.pos\n\
    \  tag startupscript\n</source>\n\n# Examples:\n# time=\"2016-02-04T06:51:03.053580605Z\"\
    \ level=info msg=\"GET /containers/json\"\n# time=\"2016-02-04T07:53:57.505612354Z\"\
    \ level=error msg=\"HTTP Error\" err=\"No such image: -f\" statusCode=404\n<source>\n\
    \  type tail\n  format /^time=\"(?<time>[^)]*)\" level=(?<severity>[^ ]*) msg=\"\
    (?<message>[^\"]*)\"( err=\"(?<error>[^\"]*)\")?( statusCode=($<status_code>\\\
    d+))?/\n  path /var/log/docker.log\n  pos_file /var/log/gcp-docker.log.pos\n \
    \ tag docker\n</source>\n\n# Example:\n# 2016/02/04 06:52:38 filePurge: successfully\
    \ removed file /var/etcd/data/member/wal/00000000000006d0-00000000010a23d1.wal\n\
    <source>\n  type tail\n  # Not parsing this, because it doesn't have anything\
    \ particularly useful to\n  # parse out of it (like severities).\n  format none\n\
    \  path /var/log/etcd.log\n  pos_file /var/log/gcp-etcd.log.pos\n  tag etcd\n\
    </source>\n\n# Multi-line parsing is required for all the kube logs because very\
    \ large log\n# statements, such as those that include entire object bodies, get\
    \ split into\n# multiple lines by glog.\n\n# Example:\n# I0204 07:32:30.020537\
    \    3368 server.go:1048] POST /stats/container/: (13.972191ms) 200 [[Go-http-client/1.1]\
    \ 10.244.1.3:40537]\n<source>\n  type tail\n  format multiline\n  multiline_flush_interval\
    \ 5s\n  format_firstline /^\\w\\d{4}/\n  format1 /^(?<severity>\\w)(?<time>\\\
    d{4} [^\\s]*)\\s+(?<pid>\\d+)\\s+(?<source>[^ \\]]+)\\] (?<message>.*)/\n  time_format\
    \ %m%d %H:%M:%S.%N\n  path /var/log/kubelet.log\n  pos_file /var/log/gcp-kubelet.log.pos\n\
    \  tag kubelet\n</source>\n\n# Example:\n# I1118 21:26:53.975789       6 proxier.go:1096]\
    \ Port \"nodePort for kube-system/default-http-backend:http\" (:31429/tcp) was\
    \ open before and is still needed\n<source>\n  type tail\n  format multiline\n\
    \  multiline_flush_interval 5s\n  format_firstline /^\\w\\d{4}/\n  format1 /^(?<severity>\\\
    w)(?<time>\\d{4} [^\\s]*)\\s+(?<pid>\\d+)\\s+(?<source>[^ \\]]+)\\] (?<message>.*)/\n\
    \  time_format %m%d %H:%M:%S.%N\n  path /var/log/kube-proxy.log\n  pos_file /var/log/gcp-kube-proxy.log.pos\n\
    \  tag kube-proxy\n</source>\n\n# Example:\n# I0204 07:00:19.604280       5 handlers.go:131]\
    \ GET /api/v1/nodes: (1.624207ms) 200 [[kube-controller-manager/v1.1.3 (linux/amd64)\
    \ kubernetes/6a81b50] 127.0.0.1:38266]\n<source>\n  type tail\n  format multiline\n\
    \  multiline_flush_interval 5s\n  format_firstline /^\\w\\d{4}/\n  format1 /^(?<severity>\\\
    w)(?<time>\\d{4} [^\\s]*)\\s+(?<pid>\\d+)\\s+(?<source>[^ \\]]+)\\] (?<message>.*)/\n\
    \  time_format %m%d %H:%M:%S.%N\n  path /var/log/kube-apiserver.log\n  pos_file\
    \ /var/log/gcp-kube-apiserver.log.pos\n  tag kube-apiserver\n</source>\n\n# Example:\n\
    # I0204 06:55:31.872680       5 servicecontroller.go:277] LB already exists and\
    \ doesn't need update for service kube-system/kube-ui\n<source>\n  type tail\n\
    \  format multiline\n  multiline_flush_interval 5s\n  format_firstline /^\\w\\\
    d{4}/\n  format1 /^(?<severity>\\w)(?<time>\\d{4} [^\\s]*)\\s+(?<pid>\\d+)\\s+(?<source>[^\
    \ \\]]+)\\] (?<message>.*)/\n  time_format %m%d %H:%M:%S.%N\n  path /var/log/kube-controller-manager.log\n\
    \  pos_file /var/log/gcp-kube-controller-manager.log.pos\n  tag kube-controller-manager\n\
    </source>\n\n# Example:\n# W0204 06:49:18.239674       7 reflector.go:245] pkg/scheduler/factory/factory.go:193:\
    \ watch of *api.Service ended with: 401: The event in requested index is outdated\
    \ and cleared (the requested history has been cleared [2578313/2577886]) [2579312]\n\
    <source>\n  type tail\n  format multiline\n  multiline_flush_interval 5s\n  format_firstline\
    \ /^\\w\\d{4}/\n  format1 /^(?<severity>\\w)(?<time>\\d{4} [^\\s]*)\\s+(?<pid>\\\
    d+)\\s+(?<source>[^ \\]]+)\\] (?<message>.*)/\n  time_format %m%d %H:%M:%S.%N\n\
    \  path /var/log/kube-scheduler.log\n  pos_file /var/log/gcp-kube-scheduler.log.pos\n\
    \  tag kube-scheduler\n</source>\n\n# Example:\n# I1104 10:36:20.242766      \
    \ 5 rescheduler.go:73] Running Rescheduler\n<source>\n  type tail\n  format multiline\n\
    \  multiline_flush_interval 5s\n  format_firstline /^\\w\\d{4}/\n  format1 /^(?<severity>\\\
    w)(?<time>\\d{4} [^\\s]*)\\s+(?<pid>\\d+)\\s+(?<source>[^ \\]]+)\\] (?<message>.*)/\n\
    \  time_format %m%d %H:%M:%S.%N\n  path /var/log/rescheduler.log\n  pos_file /var/log/gcp-rescheduler.log.pos\n\
    \  tag rescheduler\n</source>\n\n# Example:\n# I0603 15:31:05.793605       6 cluster_manager.go:230]\
    \ Reading config from path /etc/gce.conf\n<source>\n  type tail\n  format multiline\n\
    \  multiline_flush_interval 5s\n  format_firstline /^\\w\\d{4}/\n  format1 /^(?<severity>\\\
    w)(?<time>\\d{4} [^\\s]*)\\s+(?<pid>\\d+)\\s+(?<source>[^ \\]]+)\\] (?<message>.*)/\n\
    \  time_format %m%d %H:%M:%S.%N\n  path /var/log/glbc.log\n  pos_file /var/log/gcp-glbc.log.pos\n\
    \  tag glbc\n</source>\n\n# Example:\n# I0603 15:31:05.793605       6 cluster_manager.go:230]\
    \ Reading config from path /etc/gce.conf\n<source>\n  type tail\n  format multiline\n\
    \  multiline_flush_interval 5s\n  format_firstline /^\\w\\d{4}/\n  format1 /^(?<severity>\\\
    w)(?<time>\\d{4} [^\\s]*)\\s+(?<pid>\\d+)\\s+(?<source>[^ \\]]+)\\] (?<message>.*)/\n\
    \  time_format %m%d %H:%M:%S.%N\n  path /var/log/cluster-autoscaler.log\n  pos_file\
    \ /var/log/gcp-cluster-autoscaler.log.pos\n  tag cluster-autoscaler\n</source>\n\
    \n# Logs from systemd-journal for interesting services.\n<source>\n  type systemd\n\
    \  filters [{ \"_SYSTEMD_UNIT\": \"docker.service\" }]\n  pos_file /var/log/gcp-journald-docker.pos\n\
    \  read_from_head true\n  tag docker\n</source>\n\n<source>\n  type systemd\n\
    \  filters [{ \"_SYSTEMD_UNIT\": \"kubelet.service\" }]\n  pos_file /var/log/gcp-journald-kubelet.pos\n\
    \  read_from_head true\n  tag kubelet\n</source>\n\n<source>\n  type systemd\n\
    \  filters [{ \"_SYSTEMD_UNIT\": \"node-problem-detector.service\" }]\n  pos_file\
    \ /var/log/gcp-journald-node-problem-detector.pos\n  read_from_head true\n  tag\
    \ node-problem-detector\n</source>"
kind: ConfigMap
metadata:
  annotations: {}
  labels:
    addonmanager.kubernetes.io/mode: Reconcile
  name: fluentd-gcp-config-v1.2.3
  namespace: kube-system
